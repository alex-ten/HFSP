---
title: Similar exploration, different exploitation
category: closed_loop
doctype: entry
entrynum: 2
---

[Figure 2.1](#f-2-1){: .animated} shows proportions of time spent on each task and switches to each task in the two groups. This visualization demonstrates that the two groups made similar decisions when it came to *choosing* a task given a decision to switch. However, decisions about *when* to switch seems to be different across groups. The free group spent most of its time on task 1D, yet switched to it the least. Both groups switched to the R task the most, but the strategic group spent almost 40% of time on that task. From the learning progress hypothesis perspective it might seem like the strategic group failed to follow an optimal learning strategy, but bear in mind that the ultimate mastery of tasks was similar across groups, and that becoming certain about uncertainty of an event as also a learning progress. And if the process of growing certain about an uncertainty of an event takes longer, perhaps the strategic group were optimal. This could explain the prevalence of R-task trials among subjects who were explicitly informed (see figure [Figure 2.2](#f-2-2){: .animated}) about the unsolvability of one of the tasks.

{% include caption.html 
    obj='figure' 
    num=page.entrynum 
    ext='1'
    label='Differences in switching and play time between groups' %}

<a href='{{site.baseurl}}/img/time_vs_switching.svg'><img alt='time_vs_switching' src='{{site.baseurl}}/img_compressed/time_vs_switching.svg'/></a>

{% include caption.html 
    obj='figure' 
    num=page.entrynum 
    ext='2'
    label='Play time split by groups and conditions' %}

<a href='{{site.baseurl}}/img/time_on_tasks.svg'><img alt='time_on_tasks' src='{{site.baseurl}}/img_compressed/time_on_tasks.svg' style="width: 50%; height:auto; display: block; margin: 0 auto;/"></a>

One tentative explanation is that the "strategic" instructions created a knowledge gap different from one that would be naturally induced (e.g. in the F group). This might not be particularly satisfying, as it seems to push the question aside rather than answering it, since we have not established what exactly knowledge gaps are. Let's try to apply <a href='{{site.baseurl}}/pdfs/GolmanLoewenstein_2016_gaps.pdf' class='animated' target='_blank'>Golman and Loewenstein's (2016)</a> [G&L] framework to our monster task. The authors propose a general model of informational utility, in which answers to certain questions are evaluated on the basis of their material value, valence, and clarity. Since correct answers in our study (e.g. "fat and short bears prefer tacos") were not supposed to have any material value or emotional valence, we can ignore the corresponding terms in G&L's general form utility function and focus on clarity, which corresponds to the entropy of a discrete probability distribution over a set of conceived answers.

